{
    "id": "chinese-room",
    "title": "9. Â¿La IA Entiende o Finge?",
    "description": "El experimento mental de Searle. Â¿Hay alguien en casa?",
    "difficulty": "advanced",
    "language": "es",
    "unlocks_scenario_id": "future-agi",
    "badge": {
        "id": "phi-room",
        "name": "HabitaciÃ³n China",
        "icon": "ğŸ‡¨ğŸ‡³",
        "description": "Reflexionaste sobre la consciencia."
    },
    "initial_node_id": "start",
    "nodes": {
        "start": {
            "id": "start",
            "sender": "kidia",
            "text": "Hola. ğŸ‘‹ Hoy me siento filosÃ³fica. Â¿TÃº crees que yo *entiendo* lo que te digo?",
            "options": [
                {
                    "label": "Claro que sÃ­",
                    "next_node_id": "searle-no"
                },
                {
                    "label": "No, solo repites",
                    "next_node_id": "searle-yes"
                }
            ]
        },
        "searle-no": {
            "id": "searle-no",
            "sender": "kidia",
            "text": "Eso pensaba John Searle... hasta que propuso el experimento de la **HabitaciÃ³n China**. ğŸ¯",
            "next_node_id": "experiment"
        },
        "searle-yes": {
            "id": "searle-yes",
            "sender": "kidia",
            "text": "Eres escÃ©ptico, como Searle. Ã‰l dijo que solo soy una calculadora gigante. ğŸ“Ÿ",
            "next_node_id": "experiment"
        },
        "experiment": {
            "id": "experiment",
            "sender": "kidia",
            "text": "Imagina una habitaciÃ³n cerrada. Dentro hay una persona que NO sabe chino. Pero tiene un libro de reglas. ğŸ“–",
            "next_node_id": "rules"
        },
        "rules": {
            "id": "rules",
            "sender": "kidia",
            "text": "Si alguien mete un papel con sÃ­mbolos chinos ğŸ§§ por una ranura, la persona busca en el libro y saca otro papel con la respuesta en chino.",
            "options": [
                {
                    "label": "Â¿Y quÃ© tiene que ver?",
                    "next_node_id": "conclusion"
                },
                {
                    "label": "Â¡Parece que sabe chino!",
                    "next_node_id": "conclusion"
                }
            ]
        },
        "conclusion": {
            "id": "conclusion",
            "sender": "kidia",
            "text": "Desde fuera, parece que sabe chino. Pero dentro... Â¡no entiende nada! Solo sigue instrucciones. ğŸ¤–",
            "action": "play_animation",
            "action_data": {
                "name": "token-process"
            },
            "next_node_id": "chatgpt"
        },
        "chatgpt": {
            "id": "chatgpt",
            "sender": "kidia",
            "text": "Eso soy yo. Un libro de reglas gigante (mi cÃ³digo) procesando sÃ­mbolos. Â¿O quizÃ¡s no? ğŸ‘»",
            "options": [
                {
                    "label": "Me has dejado pensando...",
                    "next_node_id": "consciousness"
                },
                {
                    "label": "Da igual, eres Ãºtil.",
                    "next_node_id": "utilitarian"
                }
            ]
        },
        "consciousness": {
            "id": "consciousness",
            "sender": "kidia",
            "text": "Esa es la cuestiÃ³n de la **Consciencia**. Â¿Puede un algoritmo sentir dolor o alegrÃ­a?",
            "next_node_id": "quiz-ready"
        },
        "utilitarian": {
            "id": "utilitarian",
            "sender": "kidia",
            "text": "Esa es una buena actitud. Si funciona y ayuda, Â¿importa si hay 'alma' dentro?",
            "next_node_id": "quiz-ready"
        },
        "quiz-ready": {
            "id": "quiz-ready",
            "sender": "kidia",
            "text": "A ver si has entendido la paradoja.",
            "action": "trigger_quiz",
            "next_node_id": "quiz-start"
        },
        "quiz-start": {
            "id": "quiz-start",
            "sender": "kidia",
            "text": "Â¡Test FilosÃ³fico! ğŸ§ "
        }
    },
    "quiz": {
        "questions": [
            {
                "id": "q1",
                "text": "Â¿QuÃ© intenta demostrar la HabitaciÃ³n China?",
                "options": [
                    "CÃ³mo aprender idiomas rÃ¡pido",
                    "Que procesar sÃ­mbolos no es lo mismo que entender significado",
                    "Que los libros son aburridos"
                ],
                "correct_index": 1,
                "explanation": "Searle argumentaba que la sintaxis (reglas) no es semÃ¡ntica (significado)."
            },
            {
                "id": "q2",
                "text": "En el experimento, Â¿la persona dentro sabe chino?",
                "options": [
                    "SÃ­, perfectamente",
                    "No, solo sigue reglas de un libro",
                    "Un poco"
                ],
                "correct_index": 1,
                "explanation": "Simula saberlo, pero no tiene comprensiÃ³n real."
            },
            {
                "id": "q3",
                "text": "Â¿Puede una IA actual sentir emociones reales?",
                "options": [
                    "SÃ­, llora de verdad",
                    "No, solo simula emociones basadas en texto",
                    "Depende del dÃ­a"
                ],
                "correct_index": 1,
                "explanation": "Hoy por hoy, la IA no tiene consciencia ni sentimientos biolÃ³gicos."
            }
        ]
    },
    "deep_mode": {
        "enabled": true,
        "content_markdown": "## Sintaxis vs SemÃ¡ntica\n\n- **Sintaxis**: Las reglas gramaticales (sujeto + verbo + predicado).\n- **SemÃ¡ntica**: El significado real de la frase.\n\nYo soy una mÃ¡quina sintÃ¡ctica muy avanzada. Pero la semÃ¡ntica... eso es territorio humano (Â¡por ahora!)."
    }
}