{
    "id": "tokens-math",
    "title": "4. El Lenguaje de los N√∫meros",
    "description": "Aprende c√≥mo la IA lee tu mente (bueno, tus textos).",
    "difficulty": "intermediate",
    "language": "es",
    "unlocks_scenario_id": "neural-networks",
    "badge": {
        "id": "int-token",
        "name": "Tokenizador",
        "icon": "üî¢",
        "description": "Ves el mundo como una matriz."
    },
    "initial_node_id": "start",
    "nodes": {
        "start": {
            "id": "start",
            "sender": "kidia",
            "text": "¬°Hola! üî¢ Hoy vamos a diseccionar palabras. Para m√≠, 'Gato' no es un animal con pelo... es el n√∫mero [0.23, -0.99, 4.12].",
            "options": [
                {
                    "label": "¬øQu√© dices?",
                    "next_node_id": "vectors-intro"
                },
                {
                    "label": "¬°Eres un robot!",
                    "next_node_id": "vectors-intro"
                }
            ]
        },
        "vectors-intro": {
            "id": "vectors-intro",
            "sender": "kidia",
            "text": "Exacto. Convierto palabras en listas de n√∫meros llamadas **Vectores**. Son como coordenadas en un mapa infinito. üó∫Ô∏è",
            "next_node_id": "math-challenge-1"
        },
        "math-challenge-1": {
            "id": "math-challenge-1",
            "sender": "system",
            "text": "üßÆ CALCULADORA DE PALABRAS:\nSi 'Rey' est√° lejos de 'Mujer' y cerca de 'Hombre'...\n¬øQu√© pasa si hacemos: Rey - Hombre + Mujer = ?",
            "options": [
                {
                    "label": "Pr√≠ncipe",
                    "next_node_id": "math-wrong-1"
                },
                {
                    "label": "Reina",
                    "next_node_id": "math-correct-1"
                }
            ]
        },
        "math-wrong-1": {
            "id": "math-wrong-1",
            "sender": "kidia",
            "text": "Casi. Pr√≠ncipe ser√≠a 'Rey - Edad'. üìâ Pero si cambiamos solo el g√©nero, sale REINA.",
            "next_node_id": "math-challenge-2"
        },
        "math-correct-1": {
            "id": "math-correct-1",
            "sender": "kidia",
            "text": "¬°Bingo! üëë Las matem√°ticas del lenguaje funcionan. Vamos a por una m√°s dif√≠cil.",
            "next_node_id": "math-challenge-2"
        },
        "math-challenge-2": {
            "id": "math-challenge-2",
            "sender": "system",
            "text": "üåç GEOGRAF√çA MATEM√ÅTICA:\nPar√≠s - Francia + Jap√≥n = ?",
            "options": [
                {
                    "label": "Sushi",
                    "next_node_id": "math-wrong-2"
                },
                {
                    "label": "Tokio",
                    "next_node_id": "math-correct-2"
                }
            ]
        },
        "math-wrong-2": {
            "id": "math-wrong-2",
            "sender": "kidia",
            "text": "Jaja, qu√© rico. üç£ Pero buscamos la capital. La respuesta matem√°tica es Tokio.",
            "next_node_id": "next-word-intro"
        },
        "math-correct-2": {
            "id": "math-correct-2",
            "sender": "kidia",
            "text": "¬°Correcto! üóº Porque la relaci√≥n es 'Capital de'.",
            "next_node_id": "next-word-intro"
        },
        "next-word-intro": {
            "id": "next-word-intro",
            "sender": "kidia",
            "text": "Gracias a este mapa, puedo adivinar qu√© palabra viene despu√©s. Es como el autocompletar de tu m√≥vil, pero con esteroides. üí™",
            "options": [
                {
                    "label": "¬øC√≥mo eliges?",
                    "next_node_id": "probability-branch"
                },
                {
                    "label": "¬øY la creatividad?",
                    "next_node_id": "creativity-branch"
                }
            ]
        },
        "probability-branch": {
            "id": "probability-branch",
            "sender": "kidia",
            "text": "Puro c√°lculo. üé≤ Calculo qu√© palabra tiene m√°s probabilidad de encajar. Si digo 'Hab√≠a una...', lo m√°s probable es 'vez'.",
            "next_node_id": "quiz-ready"
        },
        "creativity-branch": {
            "id": "creativity-branch",
            "sender": "kidia",
            "text": "A veces tiro los dados. üé≤ Si siempre eligiera la palabra m√°s l√≥gica, ser√≠a aburrida. A veces elijo una menos probable para ser 'creativa'.",
            "next_node_id": "quiz-ready"
        },
        "quiz-ready": {
            "id": "quiz-ready",
            "sender": "kidia",
            "text": "¬øListo para demostrar que hablas mi idioma num√©rico?",
            "action": "trigger_quiz",
            "next_node_id": "quiz-start"
        },
        "quiz-start": {
            "id": "quiz-start",
            "sender": "kidia",
            "text": "Calculando preguntas... üìü"
        }
    },
    "quiz": {
        "questions": [
            {
                "id": "q1",
                "text": "¬øQu√© es un Token?",
                "options": [
                    "Una moneda de oro",
                    "Un trozo de texto (palabra o s√≠laba)",
                    "Un virus"
                ],
                "correct_index": 1,
                "explanation": "Los modelos de lenguaje dividen el texto en piezas llamadas tokens."
            },
            {
                "id": "q2",
                "text": "¬øQu√© son los Vectores?",
                "options": [
                    "Listas de n√∫meros que representan palabras",
                    "Flechas para disparar",
                    "Coches voladores"
                ],
                "correct_index": 0,
                "explanation": "Los vectores sit√∫an las palabras en un espacio matem√°tico."
            },
            {
                "id": "q3",
                "text": "Rey - Hombre + Mujer = ...",
                "options": [
                    "Pr√≠ncipe",
                    "Reina",
                    "Castillo"
                ],
                "correct_index": 1,
                "explanation": "Es el ejemplo cl√°sico de 'aritm√©tica sem√°ntica'."
            }
        ]
    },
    "deep_mode": {
        "enabled": true,
        "content_markdown": "## Embeddings\n\nEsos \"mapas\" se llaman **Embeddings**.\n\n- Son espacios multidimensionales (¬°cientos de dimensiones!).\n- Las palabras con significados similares est√°n cerca geom√©tricamente.\n- Gracias a esto, la IA entiende sin√≥nimos y contextos."
    }
}