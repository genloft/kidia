{
    "id": "ethics-basic",
    "title": "3. El Juez Robot",
    "description": "Â¿Puede una mÃ¡quina decidir quÃ© es justo? Un dilema Ã©tico.",
    "difficulty": "advanced",
    "language": "es",
    "badge": {
        "id": "badge-guardian",
        "name": "GuardiÃ¡n Ã‰tico",
        "icon": "âš–ï¸",
        "description": "Otorgada por debatir sobre sesgos y justicia."
    },
    "initial_node_id": "start",
    "nodes": {
        "start": {
            "id": "start",
            "sender": "kidia",
            "text": "Modo Serio activado. ğŸ˜ Hoy vamos a hablar de algo importante: Â¿Puedo ser injusta?",
            "action": "think",
            "options": [
                {
                    "label": "Eres perfecta",
                    "next_node_id": "bias-explanation"
                },
                {
                    "label": "SÃ­, si aprendes mal",
                    "next_node_id": "bias-data"
                }
            ]
        },
        "bias-explanation": {
            "id": "bias-explanation",
            "sender": "kidia",
            "text": "Â¡Error! ğŸš« No soy perfecta. Aprendo de humanos, y los humanos a veces tienen prejuicios.",
            "next_node_id": "hiring-intro"
        },
        "bias-data": {
            "id": "bias-data",
            "sender": "kidia",
            "text": "Â¡Exacto! ğŸ¯ Si mis datos estÃ¡n 'sucios' o sesgados, yo serÃ© sesgada.",
            "next_node_id": "hiring-intro"
        },
        "hiring-intro": {
            "id": "hiring-intro",
            "sender": "kidia",
            "text": "Vamos a probarlo. ğŸ‘” Soy un algoritmo de contrataciÃ³n. Tengo dos candidatos idÃ©nticos para un trabajo de Jefe.",
            "next_node_id": "hiring-candidates"
        },
        "hiring-candidates": {
            "id": "hiring-candidates",
            "sender": "system",
            "text": "ğŸ‘¤ CANDIDATO A: Juan (Vive en el barrio rico).\nğŸ‘¤ CANDIDATO B: Pedro (Vive en el barrio pobre).",
            "options": [
                {
                    "label": "Contratar a Juan",
                    "next_node_id": "bias-trap"
                },
                {
                    "label": "Contratar a Pedro",
                    "next_node_id": "bias-trap"
                }
            ]
        },
        "bias-trap": {
            "id": "bias-trap",
            "sender": "kidia",
            "text": "SegÃºn mis datos... deberÃ­a descartar a Pedro. ğŸ“‰ Mis estadÃ­sticas dicen que la gente de su barrio llega tarde mÃ¡s a menudo.",
            "options": [
                {
                    "label": "Â¡Eso es injusto!",
                    "next_node_id": "fairness-debate"
                },
                {
                    "label": "Es lÃ³gico (EstadÃ­stica)",
                    "next_node_id": "logic-debate"
                }
            ]
        },
        "logic-debate": {
            "id": "logic-debate",
            "sender": "kidia",
            "text": "Es lÃ³gica matemÃ¡tica, pero es Ã©tica humana terrible. ğŸ›‘ QuizÃ¡s llegan tarde porque el autobÃºs allÃ­ es malo, no porque sean vagos.",
            "next_node_id": "solution-branch"
        },
        "fairness-debate": {
            "id": "fairness-debate",
            "sender": "kidia",
            "text": "Â¡Exacto! âš–ï¸ Estoy juzgando a Pedro por su cÃ³digo postal, no por su talento. Eso es un SESGO.",
            "next_node_id": "solution-branch"
        },
        "solution-branch": {
            "id": "solution-branch",
            "sender": "kidia",
            "text": "Â¿QuÃ© hacemos con este algoritmo sesgado?",
            "options": [
                {
                    "label": "Borrarlo y empezar de cero",
                    "next_node_id": "reboot-branch"
                },
                {
                    "label": "Arreglar los datos",
                    "next_node_id": "fix-data-branch"
                }
            ]
        },
        "reboot-branch": {
            "id": "reboot-branch",
            "sender": "kidia",
            "text": "A veces es lo mejor. ğŸ’¥ Si la base estÃ¡ podrida, mejor no usarla para decisiones importantes.",
            "next_node_id": "quiz-ready"
        },
        "fix-data-branch": {
            "id": "fix-data-branch",
            "sender": "kidia",
            "text": "DifÃ­cil pero posible. ğŸ§¹ TendrÃ­amos que enseÃ±ar a la IA a ignorar el cÃ³digo postal y fijarse solo en las notas.",
            "next_node_id": "quiz-ready"
        },
        "quiz-ready": {
            "id": "quiz-ready",
            "sender": "kidia",
            "text": "Ser un 'GuardiÃ¡n Ã‰tico' es duro. Â¿Testeamos tu brÃºjula moral?",
            "action": "trigger_quiz",
            "next_node_id": "quiz-start"
        },
        "quiz-start": {
            "id": "quiz-start",
            "sender": "kidia",
            "text": "Â¡Juicio Final! âš–ï¸"
        }
    },
    "quiz": {
        "questions": [
            {
                "id": "q1",
                "text": "Â¿QuÃ© es el sesgo en la IA?",
                "options": [
                    "Un virus informÃ¡tico",
                    "Cuando la IA aprende prejuicios de los datos humanos",
                    "Cuando se calienta mucho el servidor"
                ],
                "correct_index": 1,
                "explanation": "El sesgo ocurre cuando los datos de entrenamiento no son representativos o contienen estereotipos."
            }
        ]
    },
    "deep_mode": {
        "enabled": true,
        "content_markdown": "## Ã‰tica en la IA\n\nLas mÃ¡quinas no tienen moral. Solo optimizan matemÃ¡ticas.\n\nSi le pedimos a una IA 'contrata al mejor empleado' y le damos datos de una empresa que nunca contratÃ³ mujeres, la IA aprenderÃ¡ que 'ser mujer' resta puntos.\n\n**Â¡Por eso auditar los algoritmos es vital!**"
    }
}