{
    "id": "ethics-basic",
    "title": "3. El Juez Robot",
    "description": "¬øPuede una m√°quina decidir qu√© es justo? Un dilema √©tico.",
    "difficulty": "advanced",
    "language": "es",
    "required_badge_id": "badge-detective",
    "isPremium": true,
    "badge": {
        "id": "badge-guardian",
        "name": "Guardi√°n √âtico",
        "icon": "‚öñÔ∏è",
        "description": "Otorgada por debatir sobre sesgos y justicia."
    },
    "initial_node_id": "start",
    "nodes": {
        "start": {
            "id": "start",
            "sender": "kidia",
            "text": "Modo Serio activado. üòê Hoy vamos a hablar de algo importante: ¬øPuedo ser injusta?",
            "action": "think",
            "options": [
                {
                    "label": "No, eres una m√°quina perfecta.",
                    "next_node_id": "bias_explanation"
                },
                {
                    "label": "Supongo que s√≠, si te programan mal.",
                    "next_node_id": "bias_data"
                }
            ]
        },
        "bias_explanation": {
            "id": "bias_explanation",
            "sender": "kidia",
            "text": "¬°Error! üö´ No soy perfecta. Aprendo de humanos, y los humanos a veces tienen prejuicios.",
            "next_node_id": "example"
        },
        "bias_data": {
            "id": "bias_data",
            "sender": "kidia",
            "text": "¬°Exacto! üéØ Pero no es solo programaci√≥n, es sobre los DATOS con los que aprendo.",
            "next_node_id": "example"
        },
        "example": {
            "id": "example",
            "sender": "kidia",
            "text": "Imagina que me ense√±an fotos de m√©dicos y solo me muestran hombres. üë®‚Äç‚öïÔ∏è ¬øQu√© pensar√© cuando vea a una mujer doctora?",
            "options": [
                {
                    "label": "Que es una enfermera.",
                    "next_node_id": "discrimination"
                },
                {
                    "label": "Que es un error.",
                    "next_node_id": "discrimination"
                }
            ]
        },
        "discrimination": {
            "id": "discrimination",
            "sender": "kidia",
            "text": "Exacto. Eso se llama **Sesgo (Bias)**. Y puede hacer que tome decisiones injustas. Por eso necesito 'Guardianes' como t√∫.",
            "action": "trigger_quiz",
            "next_node_id": "quiz-start"
        },
        "quiz-start": {
            "id": "quiz-start",
            "sender": "kidia",
            "text": "Demuestra que tienes √©tica."
        }
    },
    "quiz": {
        "questions": [
            {
                "id": "q1",
                "text": "¬øQu√© es el sesgo en la IA?",
                "options": [
                    "Un virus inform√°tico",
                    "Cuando la IA aprende prejuicios de los datos humanos",
                    "Cuando se calienta mucho el servidor"
                ],
                "correct_index": 1,
                "explanation": "El sesgo ocurre cuando los datos de entrenamiento no son representativos o contienen estereotipos."
            }
        ]
    },
    "deep_mode": {
        "enabled": true,
        "content_markdown": "## √âtica en la IA\n\nLas m√°quinas no tienen moral. Solo optimizan matem√°ticas.\n\nSi le pedimos a una IA 'contrata al mejor empleado' y le damos datos de una empresa que nunca contrat√≥ mujeres, la IA aprender√° que 'ser mujer' resta puntos.\n\n**¬°Por eso auditar los algoritmos es vital!**"
    }
}